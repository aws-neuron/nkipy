{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MLP NKIPy Tutorial\n",
                "\n",
                "This tutorial uses a simple Multi-Layer Perceptron (MLP) NKIPy kernel to demonstrate how NKIPy works with more complex neural network operations.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "from nkipy.core.trace import NKIPyKernel\n",
                "from nkipy.runtime.execute import simulate_traced_kernel, baremetal_run_traced_kernel"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Defining A Simple MLP NKIPy Kernel\n",
                "\n",
                "A simple MLP consists of:\n",
                "1. A linear transformation (matrix multiplication + bias)\n",
                "2. An activation function (SiLU/Swish)\n",
                "3. Another linear transformation\n",
                "\n",
                "This is a basic two-layer feedforward network using SiLU activation, which is commonly used in modern neural networks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def silu_kernel(x):\n",
                "    \"\"\"SiLU (Swish) activation function: x * sigmoid(x).\"\"\"\n",
                "    return x * (1 / (1 + np.exp(-x)))\n",
                "\n",
                "\n",
                "def mlp_kernel(x, weight1, bias1, weight2, bias2):\n",
                "    \"\"\"Simple MLP with two linear layers and SiLU activation.\n",
                "    \n",
                "    Args:\n",
                "        x: Input tensor [batch_size, input_dim]\n",
                "        weight1: First layer weight [input_dim, hidden_dim]\n",
                "        bias1: First layer bias [hidden_dim]\n",
                "        weight2: Second layer weight [hidden_dim, output_dim]\n",
                "        bias2: Second layer bias [output_dim]\n",
                "    \n",
                "    Returns:\n",
                "        Output tensor [batch_size, output_dim]\n",
                "    \"\"\"\n",
                "    # First linear layer\n",
                "    hidden = np.matmul(x, weight1) + bias1\n",
                "    \n",
                "    # SiLU (Swish) activation\n",
                "    hidden_activated = silu_kernel(hidden)\n",
                "    \n",
                "    # Second linear layer\n",
                "    output = np.matmul(hidden_activated, weight2) + bias2\n",
                "    \n",
                "    return output"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Running the MLP Kernel as a NumPy function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Input shape: (2, 2048)\n",
                        "Weight1 shape: (2048, 8192)\n",
                        "Bias1 shape: (8192,)\n",
                        "Weight2 shape: (8192, 2048)\n",
                        "Bias2 shape: (2048,)\n",
                        "\n",
                        "NumPy output shape: (2, 2048)\n",
                        "NumPy output range: [20500.1797, 21870.7598]\n"
                    ]
                }
            ],
            "source": [
                "# Create test data\n",
                "batch_size = 2\n",
                "input_dim = 2048\n",
                "hidden_dim = 8192\n",
                "output_dim = 2048\n",
                "\n",
                "# Input data\n",
                "x = np.random.rand(batch_size, input_dim).astype(np.float32)\n",
                "print(f\"Input shape: {x.shape}\")\n",
                "\n",
                "# Network parameters\n",
                "weight1 = np.random.rand(input_dim, hidden_dim).astype(np.float32) * 0.1\n",
                "bias1 = np.random.rand(hidden_dim).astype(np.float32) * 0.1\n",
                "weight2 = np.random.rand(hidden_dim, output_dim).astype(np.float32) * 0.1\n",
                "bias2 = np.random.rand(output_dim).astype(np.float32) * 0.1\n",
                "\n",
                "print(f\"Weight1 shape: {weight1.shape}\")\n",
                "print(f\"Bias1 shape: {bias1.shape}\")\n",
                "print(f\"Weight2 shape: {weight2.shape}\")\n",
                "print(f\"Bias2 shape: {bias2.shape}\")\n",
                "\n",
                "# Run as NumPy function\n",
                "out_numpy = mlp_kernel(x, weight1, bias1, weight2, bias2)\n",
                "print(f\"\\nNumPy output shape: {out_numpy.shape}\")\n",
                "print(f\"NumPy output range: [{np.min(out_numpy):.4f}, {np.max(out_numpy):.4f}]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tracing the MLP Kernel"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Trace the kernel\n",
                "traced_kernel = NKIPyKernel.trace(mlp_kernel)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Running the Traced Kernel with Simulation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Simulated output shape: (2, 2048)\n",
                        "Simulated output range: [20500.2129, 21870.7559]\n",
                        "Is the simulated output the same as NumPy? True\n"
                    ]
                }
            ],
            "source": [
                "out_nkipy = simulate_traced_kernel(traced_kernel, x, weight1, bias1, weight2, bias2)\n",
                "print(f\"Simulated output shape: {out_nkipy.shape}\")\n",
                "print(f\"Simulated output range: [{np.min(out_nkipy):.4f}, {np.max(out_nkipy):.4f}]\")\n",
                "print(f\"Is the simulated output the same as NumPy? {np.allclose(out_nkipy, out_numpy)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Running it On Trainium Hardware"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Baremetal output shape: (2, 2048)\n",
                        "Baremetal output range: [20500.1797, 21870.7598]\n",
                        "Is the baremetal output the same as NumPy? True\n"
                    ]
                }
            ],
            "source": [
                "# Run on Trainium hardware\n",
                "out_baremetal = baremetal_run_traced_kernel(traced_kernel, x, weight1, bias1, weight2, bias2)\n",
                "print(f\"Baremetal output shape: {out_baremetal.shape}\")\n",
                "print(f\"Baremetal output range: [{np.min(out_baremetal):.4f}, {np.max(out_baremetal):.4f}]\")\n",
                "print(f\"Is the baremetal output the same as NumPy? {np.allclose(out_baremetal, out_numpy)}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv_nkipy_local",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
